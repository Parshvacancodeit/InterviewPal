import { useState, useRef, useEffect } from "react";
import { useLocation, useNavigate } from "react-router-dom";
import { FaMicrophone, FaPause, FaStop } from "react-icons/fa";
import "../styles/InterviewPage.css";
import api from "../api/axios"; // ‚úÖ centralized axios instance

// Helper: Build the evaluation payload
const buildEvaluationPayload = (questionObj, userAnswer) => ({
  question: questionObj.question,
  reference_answer: questionObj.reference_answer,
  keywords: questionObj.keywords,
  user_answer: userAnswer,
});

function InterviewPage() {
  const location = useLocation();
  const navigate = useNavigate();
  const formData = location.state;

  useEffect(() => {
    if (!formData) {
      navigate("/interview/setup");
    }
  }, [formData, navigate]);

  if (!formData) return null;

  const { name, skill, difficulty, question, interviewId } = formData;

  const [messages, setMessages] = useState([
    { from: "ai", text: `Welcome ${name}, let's begin your ${difficulty} ${skill} interview.` },
    { from: "ai", text: question?.question || "Tell me about yourself." }
  ]);

  const [transcript, setTranscript] = useState("");
  const [recording, setRecording] = useState(false);
  const [paused, setPaused] = useState(false);
  const [loading, setLoading] = useState(false);

  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const currentQuestionRef = useRef(question);

  const handleStartRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = event => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start();
      setRecording(true);
      setPaused(false);
    } catch (err) {
      console.error("üéôÔ∏è Mic error:", err);
      alert("Microphone access denied.");
    }
  };

  const handlePauseRecording = () => {
    if (mediaRecorderRef.current?.state === "recording") {
      mediaRecorderRef.current.pause();
      setPaused(true);
    }
  };

  const handleStopRecording = () => {
    if (mediaRecorderRef.current?.state !== "inactive") {
      mediaRecorderRef.current.stop();
      setRecording(false);
      setPaused(false);

      mediaRecorderRef.current.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: "audio/webm" });

        const formDataAudio = new FormData();
        formDataAudio.append("audio", audioBlob, "recording.webm");

        setLoading(true);
        setTranscript("Transcribing...");

        try {
          const response = await api.post("/api/transcribe", formDataAudio, {
            headers: { "Content-Type": "multipart/form-data" },
          });

          const { text } = response.data;
          setTranscript(text);

          const payload = buildEvaluationPayload(currentQuestionRef.current, text);

          setMessages(prev => [...prev, { from: "user", text }]);

          try {
            const evalResponse = await api.post("/api/evaluate", payload);
            const evalResult = evalResponse.data;

            setMessages(prev => [
              ...prev,
              {
                from: "ai",
                text: `Evaluation: Overall Score - ${evalResult.score.overall}. Feedback - ${evalResult.feedback}`
              }
            ]);

            console.log("üì§ Saving answer to DB with payload:", {
  interviewId,
  question: currentQuestionRef.current.question,
  referenceAnswer: currentQuestionRef.current.reference_answer,
  userAnswer: text,
  transcript: text,
  scores: evalResult.score,
  feedback: evalResult.feedback,
});

            // ‚úÖ Save the answer
            await api.post("/api/interview-data/save-answer", {
              interviewId,
              question: currentQuestionRef.current.question,
              referenceAnswer: currentQuestionRef.current.reference_answer,
              userAnswer: text,
              transcript: text,
              scores: evalResult.score,
              feedback: evalResult.feedback,
            });

          } catch (evalErr) {
            console.error("Evaluation failed:", evalErr);
            setMessages(prev => [...prev, { from: "ai", text: "Evaluation failed." }]);
          }

          // ‚úÖ Fetch next question or end interview
          setTimeout(async () => {
            try {
              const nextQRes = await api.post("/start", {
                name:name,
                tech: skill,
                difficulty: difficulty
              });

              const nextQuestion = nextQRes.data.question;

              if (nextQuestion?.question) {
                currentQuestionRef.current = nextQuestion;
                setMessages(prev => [...prev, { from: "ai", text: nextQuestion.question }]);
              } else {
                // ‚úÖ Mark interview as complete
                await api.post("/api/interview-data/complete", { interviewId });
                setMessages(prev => [...prev, { from: "ai", text: "‚úÖ Interview completed. Thank you!" }]);
              }
            } catch (fetchErr) {
              console.error("‚ö†Ô∏è Failed to fetch next question:", fetchErr);
              setMessages(prev => [...prev, { from: "ai", text: "Error fetching next question." }]);
            } finally {
              setLoading(false);
            }
          }, 2000);

        } catch (err) {
          console.error("‚ùå Transcription failed:", err);
          alert("Transcription failed.");
          setLoading(false);
        }
      };
    }
  };

  const handleEndInterview = async () => {
    if (!interviewId) {
      alert("Interview ID not found.");
      return;
    }

    try {
      const response = await api.post("/api/interview-data/complete", {
        interviewId
      });

      if (response.data.success) {
        alert("Interview ended successfully!");
        navigate("/");
      } else {
        alert("Failed to end interview.");
      }
    } catch (err) {
      console.error("‚ùå Error ending interview:", err);
      alert("Error ending interview.");
    }
  };

  return (
    <div className="interview-wrapper">
      <div className="chat-box">
        {messages.map((msg, index) => (
          <div key={index} className={`chat-bubble ${msg.from}`}>
            {msg.text}
          </div>
        ))}
      </div>

      <div className="voice-input-box">
        <input
          type="text"
          value={loading ? "Transcribing..." : transcript}
          onChange={(e) => setTranscript(e.target.value)}
          placeholder="Your spoken answer will appear here..."
          readOnly
        />

        {!recording && (
          <button onClick={handleStartRecording} title="Start Recording">
            <FaMicrophone />
          </button>
        )}

        {recording && !paused && (
          <button onClick={handlePauseRecording} title="Pause Recording">
            <FaPause />
          </button>
        )}

        {recording && (
          <button onClick={handleStopRecording} title="Stop and Transcribe">
            <FaStop />
          </button>
        )}

        <button onClick={handleEndInterview} title="End Interview">
          End Interview
        </button>
      </div>
    </div>
  );
}

export default InterviewPage;
